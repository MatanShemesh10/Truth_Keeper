{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame saved to 'output_file_true10.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "            cleaned_text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "            return cleaned_text\n",
    "    else:\n",
    "            return text\n",
    "\n",
    "def remove_quotes(text):\n",
    "    if isinstance(text, str): \n",
    "        return text.strip('\"')\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def combine_csv_files(folder_path, output_file):\n",
    "    # Initialize an empty list to store DataFrames\n",
    "    dfs = []\n",
    "    \n",
    "    # Iterate over each file in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            # Read the CSV file into a DataFrame\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Drop rows where label is \"FAKE\"\n",
    "            df = df[df['Label'] != False]\n",
    "\n",
    "            # # Drop rows where Labels is neither \"FAKE\" nor \"REAL\"\n",
    "            df = df[(df['Label'] == True) | (df['Label'] == False)]\n",
    "                 \n",
    "            # Check if the DataFrame has a column named \"title\"\n",
    "            if 'Statement' in df.columns:\n",
    "                # Clean up the 'title' column\n",
    "                df['Statement'] = df['Statement'].apply(clean_text)\n",
    "                \n",
    "                # Remove surrounding quotation marks from 'title' column\n",
    "                df['Statement'] = df['Statement'].apply(remove_quotes)\n",
    "\n",
    "                \n",
    "                # Append the DataFrame to the list\n",
    "                dfs.append(df)\n",
    "            else:\n",
    "                print(f\"Warning: File '{filename}' does not have a 'title' column.\")\n",
    "    \n",
    "    # Combine all DataFrames into a single DataFrame\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Save the combined DataFrame to a new CSV file\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Combined DataFrame saved to '{output_file}'.\")\n",
    "\n",
    "# Replace 'folder_path' with the path to your folder containing CSV files\n",
    "folder_path = 'yo'\n",
    "# Replace 'output_file.csv' with the desired name and path of the output CSV file\n",
    "output_file = 'output_file_true10.csv'\n",
    "\n",
    "combine_csv_files(folder_path, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 files have been created in \"ariel\".\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def split_csv(input_file, output_folder, chunk_size=400):\n",
    "    # Create the output folder if it does not exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    # Read the entire CSV file\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Calculate the number of chunks\n",
    "    num_chunks = (len(df) + chunk_size - 1) // chunk_size  # This ensures we get all items\n",
    "    \n",
    "    # Split the DataFrame into chunks and save each one\n",
    "    for i in range(num_chunks):\n",
    "        chunk = df[i * chunk_size:(i + 1) * chunk_size]\n",
    "        chunk.to_csv(os.path.join(output_folder, f'chunk_{i+1}.csv'), index=False)\n",
    "\n",
    "    print(f'{num_chunks} files have been created in \"{output_folder}\".')\n",
    "\n",
    "# Specify the path to the input CSV file\n",
    "input_file = 'output_file_true7.csv'\n",
    "\n",
    "# Specify the output folder where the split files will be saved\n",
    "output_folder = 'ariel'\n",
    "\n",
    "# Call the function\n",
    "split_csv(input_file, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Jsonl files from a folder\n",
    "import glob\n",
    "\n",
    "# Define the input directory containing JSONL files\n",
    "input_directory = \"datasets_true/\"\n",
    "\n",
    "# Define the output file path for the combined JSONL file\n",
    "output_file_path = \"all_true_data2.jsonl\"\n",
    "\n",
    "# Open the output file in write mode\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    # Iterate through each JSONL file in the input directory\n",
    "    for filename in glob.glob(input_directory + \"*.jsonl\"):\n",
    "        # Open the current JSONL file in read mode\n",
    "        with open(filename, 'r') as input_file:\n",
    "            # Read each line (JSON object) from the input file\n",
    "            for line in input_file:\n",
    "                # Write the line to the output file\n",
    "                output_file.write(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
